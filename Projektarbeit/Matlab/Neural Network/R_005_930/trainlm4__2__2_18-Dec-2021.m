function [Y,Xf,Af] = trainlm4__2__2_18-Dec-2021(X,~,~)
%TRAINLM4__2__2_18-DEC-2021 neural network simulation function.
%
% Auto-generated by MATLAB, 18-Dec-2021 18:45:33.
% 
% [Y] = trainlm4__2__2_18-Dec-2021(X,~,~) takes these arguments:
% 
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 5xQ matrix, input #1 at timestep ts.
% 
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 2xQ matrix, output #1 at timestep ts.
% 
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [0.50826608;0.75224505;0.25240559;0.7524299;0.250911845];
x1_step1.gain = [0.33388061039706;0.400593992760585;0.364089031557419;0.400510983928626;0.363726553603256];
x1_step1.ymin = -1;

% Layer 1
b1 = [1.9203807277508715412;0.8132275830986370746;0.70663303628842555337;3.0931022452051450955];
IW1_1 = [-0.17176901195191002225 -0.10096546477520706997 -0.25488283211862322597 1.2404027347487203148 2.0618556611326326333;-1.8392842544506911029 -0.073249727427536187596 -0.64816118945343603741 1.4744138088651326246 -0.87285427727378728235;-0.02207556471609637555 -0.12192646601353507307 0.014424313770756895178 -0.62296326817120439845 0.71751152806537321638;-0.18395957509049229439 -0.42632973543843377673 -1.3900393865121019044 -4.4138424569903937922 3.4332314169771258605];

% Layer 2
b2 = [-0.73048433126351652867;1.2872663784740476789];
LW2_1 = [-0.61938439631693131826 0.78562495647696584111 2.9572560119540076684 -0.62991289126197214099;1.19913548160965866 -4.82144297543471545 -3.8514804335324290818 -2.5927003841663038841];

% Layer 3
b3 = [-0.20128419896641217002;0.63856011574439586198];
LW3_2 = [5.0350092306760059202 2.510366061369307733;0.92276896714869494076 -0.12802633174615582479];

% Layer 4
b4 = [0.90118013327727042316;0.0056855107926511716521];
LW4_3 = [0.10391024421534174327 -1.3607137158398061594;0.53391202202181886616 0.15288870917259361759];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = [0.585808911511449;0.568900823163935];
y1_step1.xoffset = [-1.78720142;-6.54522631];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
  X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
  Q = size(X{1},2); % samples/series
else
  Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS

    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = tansig_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Layer 3
    a3 = tansig_apply(repmat(b3,1,Q) + LW3_2*a2);
    
    % Layer 4
    a4 = repmat(b4,1,Q) + LW4_3*a3;
    
    % Output 1
    Y{1,ts} = mapminmax_reverse(a4,y1_step1);
end

% Final Delay States
Xf = cell(1,0);
Af = cell(4,0);

% Format Output Arguments
if ~isCellX
  Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
  y = bsxfun(@minus,x,settings.xoffset);
  y = bsxfun(@times,y,settings.gain);
  y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
  x = bsxfun(@minus,y,settings.ymin);
  x = bsxfun(@rdivide,x,settings.gain);
  x = bsxfun(@plus,x,settings.xoffset);
end
